{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"01. get_train_data.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"3b36d0ce020b46849d3f8575ae7d4ed9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e06a93b3066d40c78173202bbbd707d4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ad9ffc2a926e456bafe29cdabfdbb3e1","IPY_MODEL_c3ab6607340f41668e6f432597df429e","IPY_MODEL_62c2881d2fb24c4e87f39d46b57b48a1"]}},"e06a93b3066d40c78173202bbbd707d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ad9ffc2a926e456bafe29cdabfdbb3e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d654b0e06b4344be820fe545e2e3f97e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_204822fce5f04d7b8dea95220370e89e"}},"c3ab6607340f41668e6f432597df429e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_816b4b86a78444c9b16ecd1673cfea11","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1789735,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1789735,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_252d61f6f0934a439836aa4a88dff7b3"}},"62c2881d2fb24c4e87f39d46b57b48a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dc6fa2af7b824aa2a444c91b1884018c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.71M/1.71M [00:00&lt;00:00, 1.79MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_467f169f0df54a1dadf53259ed68e109"}},"d654b0e06b4344be820fe545e2e3f97e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"204822fce5f04d7b8dea95220370e89e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"816b4b86a78444c9b16ecd1673cfea11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"252d61f6f0934a439836aa4a88dff7b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dc6fa2af7b824aa2a444c91b1884018c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"467f169f0df54a1dadf53259ed68e109":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"Rv8v5z2k4PVJ"},"source":["# Data Loaders\n","\n","\n","В этом ноутбуке описывается процесс формирования обучающей выборки для обучения модели классификации жестов в дальнейшем.\n","\n","Для запуска данного ноутбука необходимо выполнить следующие команды:\n","\n","1. Загрузить данные с помощью команды ниже — для этого потребуется около 90 GB на диске или виртуальном хранилище.\n","```bash\n","sh download_data.sh\n","```\n","\n","    - Данная команда автоматически загрузит данные в директорию `./INPUT_DATA/TRAIN_DATA/`.\n","\n","    - Скачанные `zip`- архивы будут доступны в директории `./INPUT_DATA/ZIP/`\n","\n","2. Установить зависимости:\n","\n","```bash\n","pip install -r requirements.txt\n","```\n","\n","## Алгоритм\n","\n","## Код\n","\n","Если используется `google.colab`, то выполните следующий код."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LK_fUsV35I-L","executionInfo":{"status":"ok","timestamp":1625643788137,"user_tz":-180,"elapsed":12787,"user":{"displayName":"Aleksadnr Shirokov","photoUrl":"","userId":"08072078113294094856"}},"outputId":"9126a09b-1149-403f-e0cf-4b0621007b6d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VZj9VxMq7G38"},"source":["!pip install -r drive/MyDrive/detectime/requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-MhxJPp7IYj","executionInfo":{"status":"ok","timestamp":1625643848577,"user_tz":-180,"elapsed":261,"user":{"displayName":"Aleksadnr Shirokov","photoUrl":"","userId":"08072078113294094856"}},"outputId":"0a0e8adb-e70a-4f35-a8b7-6fa1ca52b80f"},"source":["cd drive/MyDrive/detectime/"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/detectime\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PArhrSngp2oT"},"source":["Подключим библиотеки."]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"p3xmHWlo4PVL","executionInfo":{"status":"ok","timestamp":1625644335296,"user_tz":-180,"elapsed":235,"user":{"displayName":"Aleksadnr Shirokov","photoUrl":"","userId":"08072078113294094856"}},"outputId":"364b610a-9d04-4762-bf21-c6580a1d0670"},"source":["import os\n","import sys\n","import cv2\n","import json\n","import logging\n","import pandas as pd\n","import seaborn as sns\n","import torch\n","import face_detection as fd\n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","\n","sys.path.append('.')\n","from definitions import ROOT_DIR\n","from detectime.augmentations import (\n","    result_crop\n",")\n","from detectime.maskrcnn import (\n","    load_model_custom\n",")\n","from mrcnn.config import Config\n","from detectime.utils import read_image\n","\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","\n","log = logging.getLogger(__name__)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["{\"asctime\": \"2021-07-07 07:52:15\", \"name\": \"matplotlib.pyplot\", \"filename\": \"pyplot.py\", \"levelname\": \"DEBUG\", \"message\": \"Loaded backend module://ipykernel.pylab.backend_inline version unknown.\"}\n","The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qHWvRMGT4PVN"},"source":["Пропишем пути к источникам данных."]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"TS0Kjce34PVN","executionInfo":{"status":"ok","timestamp":1625643877708,"user_tz":-180,"elapsed":238,"user":{"displayName":"Aleksadnr Shirokov","photoUrl":"","userId":"08072078113294094856"}}},"source":["DATA_PATH = ROOT_DIR / 'data'\n","NOTEBOOK_PATH = ROOT_DIR / 'notebooks'\n","INPUT_DATA = DATA_PATH / 'INPUT_DATA'\n","INPUT_IMAGES_FOLDER = INPUT_DATA / 'TRAIN_DATA'\n","TRAIN_IMG_FOLDER = INPUT_DATA / 'TRAIN_IMG'\n","SAVE_TRAIN_IMAGES_HANDS = TRAIN_IMG_FOLDER / 'HANDS'\n","SAVE_TRAIN_IMAGES_FACES= TRAIN_IMG_FOLDER / 'FACES'\n","\n","JSON_FOLDER = INPUT_DATA / 'JSON'\n","FACES_JSON_PRETRAINED = JSON_FOLDER / 'train_with_bboxes.json'\n","TRAIN_LABELS = INPUT_DATA / 'train.csv'\n","HAND_DETECTION_FOLDER = ROOT_DIR / 'model' / 'mask_rcnn_hand_detection.h5'\n"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SquKNt2y4PVN"},"source":["Загрузим основной конфиг из файла `./config.yml`."]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"661jHYdG4PVO","executionInfo":{"status":"ok","timestamp":1625643879116,"user_tz":-180,"elapsed":448,"user":{"displayName":"Aleksadnr Shirokov","photoUrl":"","userId":"08072078113294094856"}}},"source":["import yaml\n","from detectime.utils import convert_dict_to_tuple\n","\n","CONFIG_PATH = ROOT_DIR / 'config.yml'\n","\n","with open(CONFIG_PATH) as f:\n","    data = yaml.safe_load(f)\n","config = convert_dict_to_tuple(dictionary=data)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"smKTKysX4PVO"},"source":["Загрузим все необходимое для модели обнаружения лиц."]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["3b36d0ce020b46849d3f8575ae7d4ed9","e06a93b3066d40c78173202bbbd707d4","ad9ffc2a926e456bafe29cdabfdbb3e1","c3ab6607340f41668e6f432597df429e","62c2881d2fb24c4e87f39d46b57b48a1","d654b0e06b4344be820fe545e2e3f97e","204822fce5f04d7b8dea95220370e89e","816b4b86a78444c9b16ecd1673cfea11","252d61f6f0934a439836aa4a88dff7b3","dc6fa2af7b824aa2a444c91b1884018c","467f169f0df54a1dadf53259ed68e109"]},"id":"FBUlF5X84PVO","executionInfo":{"status":"ok","timestamp":1625643902806,"user_tz":-180,"elapsed":7939,"user":{"displayName":"Aleksadnr Shirokov","photoUrl":"","userId":"08072078113294094856"}},"outputId":"a67485eb-bcf0-409a-ca8b-8ba271e558ea"},"source":["device_name = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device = torch.device(device_name)\n","\n","model_detector_faces = fd.build_detector(\n","        config.detection.detector_type,\n","        confidence_threshold=.5,\n","        nms_iou_threshold=.3,\n","        device=device,\n","        max_resolution=640\n",")\n","print('device', device_name)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Downloading: \"https://folk.ntnu.no/haakohu/RetinaFace_mobilenet025.pth\" to /root/.cache/torch/hub/checkpoints/RetinaFace_mobilenet025.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b36d0ce020b46849d3f8575ae7d4ed9","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/1.71M [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["device cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"AhCt0nmd4PVO"},"source":["Теперь все необходимое для модуля обнаружения рук.\n","Параметр `DETECTION_MIN_CONFIDENCE` можно варьировать, но все же выставим\n","большую вероятность того, что найденный объект является рукой - так мы повысим\n","качество выборки для обучения.\n"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"F5OAcpEZ4PVP","executionInfo":{"status":"ok","timestamp":1625643941429,"user_tz":-180,"elapsed":27756,"user":{"displayName":"Aleksadnr Shirokov","photoUrl":"","userId":"08072078113294094856"}},"outputId":"5d9fc2d5-5c68-4562-c4ca-a9e4d1c8df72"},"source":["class HandConfig(Config):\n","    NAME = \"hand\"\n","    IMAGES_PER_GPU = 1\n","    NUM_CLASSES = 1 + 1\n","    STEPS_PER_EPOCH = 10\n","    DETECTION_MIN_CONFIDENCE = 0.99\n","\n","\n","class InferenceConfig(HandConfig):\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1\n","\n","model_detector_hands = load_model_custom(\n","    InferenceConfig(),\n","    str(HAND_DETECTION_FOLDER)\n",")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["(None, None, None, 1024)\n","{\"asctime\": \"2021-07-07 07:45:18\", \"name\": \"tensorflow\", \"filename\": \"deprecation.py\", \"levelname\": \"WARNING\", \"message\": \"From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/normalization.py:534: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\\nInstructions for updating:\\nColocations handled automatically by placer.\"}\n","(None, None, None, 1024)\n","{\"asctime\": \"2021-07-07 07:45:21\", \"name\": \"tensorflow\", \"filename\": \"deprecation.py\", \"levelname\": \"WARNING\", \"message\": \"From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\\nInstructions for updating:\\nThe `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\"}\n","{\"asctime\": \"2021-07-07 07:45:22\", \"name\": \"tensorflow\", \"filename\": \"deprecation.py\", \"levelname\": \"WARNING\", \"message\": \"From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\\nInstructions for updating:\\nUse fn_output_signature instead\"}\n","{\"asctime\": \"2021-07-07 07:45:23\", \"name\": \"h5py._conv\", \"filename\": \"attrs.py\", \"levelname\": \"DEBUG\", \"message\": \"Creating converter from 3 to 5\"}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LWAay5B24PVP"},"source":["Теперь напишем функцию, способ работы которой описан выше в разделе *Алгоритм*."]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"gvYABwqP4PVP","executionInfo":{"status":"ok","timestamp":1625655057004,"user_tz":-180,"elapsed":385,"user":{"displayName":"Aleksadnr Shirokov","photoUrl":"","userId":"08072078113294094856"}}},"source":["def get_train_data(data_df,\n","                   detector_faces,\n","                   detector_hands,\n","                   output_path,\n","                   file_name='hands.json',\n","                   crop_coefficient=1.5,\n","                   crop_hand_coefficient=1.5,\n","                   save_per_num_images=100,\n","                   return_data=True,\n","                   verbose=False):\n","    if os.path.exists(JSON_FOLDER / file_name):\n","        with open(str(JSON_FOLDER / file_name), 'r') as file:\n","            result_arr = json.load(file)\n","            log.info('loaded file')\n","    else:\n","        result_arr = []\n","    log.info(f'Savedir hands: {output_path}')\n","    if not os.path.exists(output_path):\n","        os.makedirs(output_path)\n","    indices = list(data_df.index)\n","    frames = data_df.frame_path.values\n","    labels = data_df.label.values\n","\n","    for idx, image_path, label in tqdm(zip(indices, frames, labels), \n","                                       total=len(data_df), desc='find hands'):\n","        img_path = str(INPUT_IMAGES_FOLDER / image_path)\n","        if not os.path.isfile(img_path):\n","            log.info(f'NO SUCH FILE {img_path}')\n","            continue\n","        else:\n","            img = read_image(img_path)\n","            # DETECTOR FACES\n","            detections = detector_faces.detect(img)\n","            all_faces = []\n","            for det in detections:\n","                x1, y1, x2, y2, s = det.tolist()\n","                w = x2 - x1\n","                h = y2 - y1\n","                bbox = [round(x1), round(y1), round(w), round(h)]\n","                all_faces.append(bbox)\n","            # DETECT HANDS\n","            all_hands = detector_hands.detect([img], verbose=0)[0]['rois']\n","\n","            # AREA\n","            area = []\n","            faces_and_hands = []\n","\n","            # CROP FACES\n","            for face in all_faces:\n","                for hand in all_hands:\n","                    x3, y3, x4, y4 = result_crop(\n","                        img,\n","                        face,\n","                        crop_coefficient=crop_coefficient\n","                    )\n","                    y1, x1, y2, x2 = hand\n","\n","                    left_x, left_y = max(x1, x3), max(y1, y3)\n","                    right_x, right_y = min(x2, x4), min(y2, y4)\n","\n","                    width, height = right_x - left_x, right_y - left_y\n","                    if width <= 0 or height <= 0:\n","                        area.append(0)\n","                    else:\n","                        area.append(width * height)\n","                    faces_and_hands.append((face, hand))\n","            if area:\n","                max_area = max(area)\n","                if max_area != 0:\n","                    index_of_max_area = area.index(max_area)\n","                    index_of_face_hand = faces_and_hands[index_of_max_area]\n","                    final_face, final_hand = index_of_face_hand\n","                    y1, x1, y2, x2 = final_hand\n","                    if label == 3:\n","                        x1, y1, x2, y2 = result_crop(\n","                            img,\n","                            [x1, y1, x2-x1, y2-y1],\n","                            crop_coefficient=crop_hand_coefficient\n","                            )\n","                    item = {\n","                        'frame_path': image_path,\n","                        'video_name': data_df.video_name.iloc[idx],\n","                        'frame_id': int(data_df.frame_id.iloc[idx]),\n","                        'label': int(label),\n","                        'bbox': [int(x1), int(y1), int(x2), int(y2)]\n","                    }\n","                    result_arr.append(item)\n","                    if verbose:\n","                        log.info(f'saved picture {image_path}')\n","                        \n","        if idx % save_per_num_images == 0 and idx > 0:\n","            with open(str(output_path / file_name), 'w') as file:\n","                json.dump(result_arr, file, indent=4)\n","                \n","    with open(str(output_path / file_name), 'w') as file:\n","        json.dump(result_arr, file, indent=4)\n","    if return_data:\n","        return result_arr\n"],"execution_count":46,"outputs":[]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"9PvuYd1e4PVQ"},"source":["Загрузим данные."]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"vggdLm9t4PVQ","executionInfo":{"status":"ok","timestamp":1625645374244,"user_tz":-180,"elapsed":751,"user":{"displayName":"Aleksadnr Shirokov","photoUrl":"","userId":"08072078113294094856"}}},"source":["CLASS_NAME2LABEL_DICT = {\n","    'no_gesture': 0,\n","    'stop': 1,\n","    'victory': 2,\n","    'mute': 3,\n","    'ok': 4,\n","    'like': 5,\n","    'dislike': 6\n","}\n","\n","train_data = pd.read_csv(str(TRAIN_LABELS))\n","train_data['label'] = train_data['class_name'].map(CLASS_NAME2LABEL_DICT)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0HbNRGPN4PVR"},"source":["Исключим данные, помеченные в качестве `no_gesture` - будем получать данные только для 6 классов."]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"DGHFlcOj4PVR","executionInfo":{"status":"ok","timestamp":1625645374589,"user_tz":-180,"elapsed":4,"user":{"displayName":"Aleksadnr Shirokov","photoUrl":"","userId":"08072078113294094856"}},"outputId":"84a1e71e-6a0e-439e-e7c1-a124396b5aaf"},"source":["train_data_gestures = train_data[train_data['label'] != 0]\n","print(train_data_gestures.shape)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["(175174, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"nN4B8iRW4PVS","executionInfo":{"status":"ok","timestamp":1625645380899,"user_tz":-180,"elapsed":5690,"user":{"displayName":"Aleksadnr Shirokov","photoUrl":"","userId":"08072078113294094856"}},"outputId":"781d89ac-31f9-4ba9-9894-f799e3473310"},"source":["from pathlib import Path\n","\n","exists_pictures = []\n","\n","for dirname, _, filenames in os.walk(INPUT_IMAGES_FOLDER):\n","    for filename in filenames:\n","        video_plus_picture = list(Path(os.path.join(dirname, filename)).parts)[-2:]\n","        frame_path = '/'.join(video_plus_picture)\n","        exists_pictures.append(frame_path)\n","\n","len(exists_pictures)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["204547"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"94J52IVV4PVS","executionInfo":{"status":"ok","timestamp":1625645449316,"user_tz":-180,"elapsed":247,"user":{"displayName":"Aleksadnr Shirokov","photoUrl":"","userId":"08072078113294094856"}},"outputId":"272cc336-5780-4afb-c037-35efe51468cb"},"source":["train = (\n","    train_data_gestures[\n","        train_data_gestures['frame_path']\n","            .isin(exists_pictures)\n","    ].reset_index(drop=True)\n",")\n","train.shape"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(174371, 5)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"dcbTJUAY4PVT"},"source":["Начнем получение тренировочных данных."]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"0dEp5NMN4PVT","executionInfo":{"status":"ok","timestamp":1625655887044,"user_tz":-180,"elapsed":238,"user":{"displayName":"Aleksadnr Shirokov","photoUrl":"","userId":"08072078113294094856"}}},"source":["data = get_train_data(train,\n","                      model_detector_faces,\n","                      model_detector_hands,\n","                      JSON_FOLDER,\n","                      file_name='hands.json',\n","                      crop_coefficient=1.5,\n","                      crop_hand_coefficient=1.5,\n","                      save_per_num_images=100,\n","                      return_data=True,\n","                      verbose=False\n","                      )"],"execution_count":50,"outputs":[]}]}